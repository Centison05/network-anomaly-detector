{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cd45cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¹ Starting full leakage-safe balanced XGBoost pipeline...\n",
      "\n",
      "Original shape: (2604998, 79)\n",
      "âœ… After full de-duplication: 2303903\n",
      "âœ… Balanced dataset shape: (1190380, 79) | Benign:Attack = {0: 892785, 1: 297595}\n",
      "Train size: (952304, 78), Test size: (238076, 78)\n",
      "\n",
      "ðŸ”Ž Checking for overlap between train/test...\n",
      "Common rows between train/test: 0\n",
      "âœ… No overlapping rows found.\n",
      "\n",
      "ðŸ§  Dropping 29 highly correlated features: ['Fwd IAT Std', 'Bwd Packet Length Std', 'Idle Max', 'Packet Length Std', 'Idle Mean', 'Bwd Packet Length Max', 'Fwd IAT Max', 'Flow IAT Max', 'Idle Min', 'Bwd Packet Length Mean']...\n",
      "ðŸ“Š Dummy baseline accuracy: 0.750\n",
      "\n",
      "ðŸ§  Sanity test ROC-AUC (random labels): 0.530\n",
      "\n",
      "--- Verification Summary ---\n",
      "Majority baseline (accuracy): 0.750\n",
      "Sanity test ROC-AUC (random labels): 0.530\n",
      "Real model accuracy: 0.999\n",
      "Real model ROC-AUC: 1.000\n",
      "\n",
      "Leakage Status: âœ… PASS (No leakage detected)\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    178557\n",
      "           1       1.00      1.00      1.00     59519\n",
      "\n",
      "    accuracy                           1.00    238076\n",
      "   macro avg       1.00      1.00      1.00    238076\n",
      "weighted avg       1.00      1.00      1.00    238076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "from sklearn.utils import resample\n",
    "\n",
    "print(\"Starting leakage-safe XGBoost pipeline...\\n\")\n",
    "\n",
    "# 1. Load dataset\n",
    "data_path = r\"C:\\Users\\cmhub\\Desktop\\network-anomaly-detector-starter\\data\\MachineLearningCSV\\MachineLearningCVE\\CICIDS2017_clean_binary.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "print(\"Original shape:\", df.shape)\n",
    "\n",
    "# 2. Remove duplicates\n",
    "df = df.drop_duplicates(subset=df.columns.difference(['Label']))\n",
    "print(\"After de-duplication:\", len(df))\n",
    "\n",
    "# 3. Handle class imbalance (downsample benign)\n",
    "benign_df = df[df['Label'] == 0]\n",
    "attack_df = df[df['Label'] == 1]\n",
    "ratio = 3  # keep 3 benign for each attack\n",
    "benign_down = resample(\n",
    "    benign_df,\n",
    "    replace=False,\n",
    "    n_samples=min(len(attack_df) * ratio, len(benign_df)),\n",
    "    random_state=42\n",
    ")\n",
    "df_balanced = (\n",
    "    pd.concat([benign_down, attack_df])\n",
    "    .sample(frac=1, random_state=42)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "print(f\"Balanced dataset shape: {df_balanced.shape}\")\n",
    "print(f\"Class distribution: {df_balanced['Label'].value_counts().to_dict()}\")\n",
    "\n",
    "# 4. Split features and labels\n",
    "X = df_balanced.drop(columns=['Label'])\n",
    "y = df_balanced['Label']\n",
    "\n",
    "# 5. Stratified train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "print(f\"Train size: {X_train.shape}, Test size: {X_test.shape}\")\n",
    "\n",
    "# 6. Verify no overlap between train/test\n",
    "print(\"\\nChecking for overlap between train/test...\")\n",
    "common_rows = pd.merge(X_train, X_test)\n",
    "print(f\"Common rows: {len(common_rows)}\")\n",
    "if len(common_rows) == 0:\n",
    "    print(\"No overlapping rows detected.\")\n",
    "else:\n",
    "    print(\"Overlap detected â€” additional cleaning may be required.\")\n",
    "\n",
    "# 7. Drop highly correlated features\n",
    "train_corr_df = X_train.copy()\n",
    "train_corr_df['Label'] = y_train\n",
    "corrs = train_corr_df.corr(numeric_only=True)['Label'].abs().sort_values(ascending=False)\n",
    "leaky_cols = corrs[corrs > 0.15].index.drop('Label', errors='ignore').tolist()\n",
    "print(f\"\\nDropping {len(leaky_cols)} highly correlated features:\")\n",
    "print(leaky_cols[:10], \"...\" if len(leaky_cols) > 10 else \"\")\n",
    "X_train = X_train.drop(columns=leaky_cols, errors='ignore')\n",
    "X_test = X_test.drop(columns=leaky_cols, errors='ignore')\n",
    "\n",
    "# 8. Baseline model\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "dummy.fit(X_train, y_train)\n",
    "dummy_acc = dummy.score(X_test, y_test)\n",
    "print(f\"\\nDummy baseline accuracy: {dummy_acc:.3f}\")\n",
    "\n",
    "# 9. Define XGBoost pipeline\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=len(y_train[y_train == 0]) / len(y_train[y_train == 1]),\n",
    "    n_jobs=-1,\n",
    "    eval_metric='auc',\n",
    "    random_state=42\n",
    ")\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', xgb_clf)\n",
    "])\n",
    "\n",
    "# 10. Sanity test with random labels\n",
    "y_perm = np.random.permutation(y_train)\n",
    "sanity_model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', xgb.XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        n_jobs=-1,\n",
    "        eval_metric='auc',\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "sanity_model.fit(X_train, y_perm)\n",
    "y_proba_perm = sanity_model.predict_proba(X_test)[:, 1]\n",
    "sanity_auc = roc_auc_score(y_test, y_proba_perm)\n",
    "print(f\"\\nSanity test ROC-AUC (random labels): {sanity_auc:.3f}\")\n",
    "\n",
    "# 11. Real model training\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "real_acc = accuracy_score(y_test, y_pred)\n",
    "real_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# 12. Evaluate leakage status\n",
    "status = \"PASS (No leakage detected)\" if sanity_auc < 0.6 else \"FAIL (Potential leakage remains!)\"\n",
    "\n",
    "# 13. Summary\n",
    "print(\"\\n--- Verification Summary ---\")\n",
    "print(f\"Majority baseline accuracy: {dummy_acc:.3f}\")\n",
    "print(f\"Sanity test ROC-AUC: {sanity_auc:.3f}\")\n",
    "print(f\"Model accuracy: {real_acc:.3f}\")\n",
    "print(f\"Model ROC-AUC: {real_auc:.3f}\")\n",
    "print(f\"Leakage status: {status}\\n\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
